{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting seasonal effects and trends, calculating moving average and other window statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import statistics\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot, lag_plot, register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from pandas.tseries.offsets import *\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import calendar\n",
    "calendar.setfirstweekday(calendar.MONDAY) # first week day\n",
    "\n",
    "from datetime import datetime, time, date, timedelta\n",
    "\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import MO, TU, WE, TH, FR, SA\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas settings\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotseasonal(res, axes):\n",
    "    res.observed.plot(ax=axes[0], legend=False)\n",
    "    axes[0].set_ylabel('Observed')\n",
    "    res.trend.plot(ax=axes[1], legend=False)\n",
    "    axes[1].set_ylabel('Trend')\n",
    "    res.seasonal.plot(ax=axes[2], legend=False)\n",
    "    axes[2].set_ylabel('Seasonal')\n",
    "    res.resid.plot(ax=axes[3], legend=False)\n",
    "    axes[3].set_ylabel('Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_week_of_month(year, month, day):\n",
    "    x = np.array(calendar.monthcalendar(year, month))\n",
    "    week_of_month = np.where(x == day)[0][0] + 1\n",
    "    return(week_of_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source 1...\n",
    "file = os.path.join(data_path, '')\n",
    "data = pd.read_excel(file, header = [0, 1])\n",
    "\n",
    "# data source 2...\n",
    "file_2 = os.path.join(data_path, '')\n",
    "data_new = pd.read_csv(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "data.columns = ['', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing date format\n",
    "data['Datum'] = data['Datum'].apply(lambda x: datetime.strptime(x, '%d.%m.%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding\n",
    "data = pd.get_dummies(data, columns=[''], drop_first=False)\n",
    "corr = data_for_exploration.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data (append or join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing index and sort\n",
    "data.set_index(pd.DatetimeIndex(data['Datum']), inplace = True, drop = False)\n",
    "data_new.set_index(pd.DatetimeIndex(data_new['Datum']), inplace = True, drop = False)\n",
    "data.sort_index(inplace=True)\n",
    "data = data.append(data_new, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, data_new, how = 'outer', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 4))\n",
    "\n",
    "x = data['Datum']\n",
    "\n",
    "plt.plot(x, data[''], label = '')\n",
    "plt.plot(x, data[''], label='')\n",
    "# Vertical lines, e.g. to show the days of ice jams\n",
    "plt.vlines(data_new['Datum'], ymin, ymax, color = 'orange')\n",
    "plt.vlines(data_new['Datum'], ymin, ymax, color = 'green')\n",
    "\n",
    "#If some period is needed:\n",
    "#ymin, ymax = plt.ylim()\n",
    "#plt.xlim('2019-02', '2019-08')\n",
    "\n",
    "plt.ylabel('N')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality and trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To analyze seasonality: fill missing days with NANs (wokrdays in that case!)\n",
    "data.reindex(pd.date_range('2015-01-01', '2020-01-30', freq = BDay()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1_ant = seasonal_decompose(data.iloc[2:][''], freq = 7) #week \n",
    "res_2_ant = seasonal_decompose(data[''], freq = 30)\n",
    "res_3_ant = seasonal_decompose(data.iloc[:-22][''], freq = 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with only weekdays\n",
    "res_1_ant.seasonal.plot(figsize = (20, 5))\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.gca().set_xlim([date(2015, 1, 3), date(2015, 5, 28)])\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m (%a)'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=(MO, TU, WE, TH, FR)))\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boxplots\n",
    "sns.set(rc={'figure.figsize':(8, 4)})\n",
    "sns.boxplot(data = data, y = data[''], x = data['Tag'], \n",
    "            order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'], \n",
    "            palette = 'muted', showfliers = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2_ant.seasonal.plot(figsize = (20, 5))\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.gca().set_xlim([date(2015, 1, 3), date(2016, 5, 28)])\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%y'))\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_3_ant.seasonal.plot(figsize = (20, 5))\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.gca().set_xlim([date(2015, 1, 3), date(2016, 5, 28)])\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%y'))\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Week+Month+Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=4, sharex=True, figsize=(19, 5))\n",
    "\n",
    "plotseasonal(res_1_ant, axes[:,0])\n",
    "plotseasonal(res_2_ant, axes[:,1])\n",
    "plotseasonal(res_3_ant, axes[:,2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations (including autocorrelation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 5))\n",
    "autocorrelation_plot(data[''])\n",
    "plt.ylim(-0.2, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last 252 days closer\n",
    "fig, ax = plt.subplots(1, 1, figsize=(17, 5))\n",
    "fig = plot_acf(data[''], lags = 260, ax = ax)\n",
    "plt.ylim(-0.1, 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[''].corr(data[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag-features and other time-related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid information leakage (by prediction for 3 days ahead, lag feature t-2 cannot be used)\n",
    "for i in range(1, 15):\n",
    "    data[' t-{}'.format(i)] = data_for_exploration[''].shift(i)\n",
    "for i in range(1, 15):\n",
    "    data[' t-{}'.format(i)] = data[''].shift(i)\n",
    "    \n",
    "# Future lags\n",
    "data[' t+{}'] = data[''].shift(1)\n",
    "data[' t+{}'] = data[''].shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by week\n",
    "#anfrage_antrag_w = data.resample('W-FRI').agg({\n",
    "data_w = data.resample('W').agg({\n",
    "    '': np.sum, \n",
    "    '': 'max'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month and year as columns, enumarate weeks within year/month\n",
    "data['Month'] = data.index.month\n",
    "data['Year'] = data.index.year\n",
    "data['Day'] = data.index.day\n",
    "data['Week_number_within_year'] = data.index.week\n",
    "# Enumerate weeks within month\n",
    "data['Week_number_within_month'] =\\\n",
    "       data.apply(lambda row: get_week_of_month(int(row['Year']), int(row['Month']), int(row['Day'])), axis = 1)\n",
    "data = data.drop(['Day'], 1)\n",
    "data['Year + month'] = pd.to_datetime(data.index).strftime(\"%Y-%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window statistics (past)\n",
    "for width in (4, 8, 12, 16, 20, 24):\n",
    "    shifted_dataframe = data.shift(3) # Fix if no information leakage\n",
    "    data['_sum_window-{}'.format(width)] = shifted_dataframe[''].rolling(window = width).sum()\n",
    "    data['_mean_window-{}'.format(width)] = shifted_dataframe[''].rolling(window = width).mean()\n",
    "# Window for the future\n",
    "for width in (4, 8, 12, 16, 20, 24):\n",
    "    data['_sum_window+{}'.format(width)] = data[''].rolling(window = width).sum().shift(-1*width)\n",
    "    data['_mean_window+{}'.format(width)] = data[''].rolling(window = width).mean().shift(-1*width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last days closer\n",
    "fig, ax = plt.subplots(1, 1, figsize=(17, 5))\n",
    "fig = plot_acf(data[''], lags = 60, ax = ax)\n",
    "plt.ylim(-0.2, 0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average\n",
    "def plotMovingAverage(series, window, plot_intervals=False, scale=1.96, plot_anomalies=False):\n",
    "\n",
    "    \"\"\"\n",
    "        series - dataframe with timeseries\n",
    "        window - rolling window size \n",
    "        plot_intervals - show confidence intervals\n",
    "        plot_anomalies - show anomalies \n",
    "\n",
    "    \"\"\"\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.title(\"Moving average\\n window size = {}\".format(window))\n",
    "    plt.plot(rolling_mean, \"g\", label=\"Rolling mean trend\")\n",
    "\n",
    "    # Plot confidence intervals for smoothed values\n",
    "    if plot_intervals:\n",
    "        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n",
    "        deviation = np.std(series[window:] - rolling_mean[window:])\n",
    "        lower_bond = rolling_mean - (mae + scale * deviation)\n",
    "        upper_bond = rolling_mean + (mae + scale * deviation)\n",
    "        plt.plot(upper_bond, \"r--\", label=\"Upper Bond / Lower Bond\")\n",
    "        plt.plot(lower_bond, \"r--\")\n",
    "        \n",
    "        # Having the intervals, find abnormal values\n",
    "        if plot_anomalies:\n",
    "            anomalies = pd.DataFrame(index=series.index, columns=series.columns)\n",
    "            anomalies[series<lower_bond] = series[series<lower_bond]\n",
    "            anomalies[series>upper_bond] = series[series>upper_bond]\n",
    "            plt.plot(anomalies, \"ro\", markersize=10)\n",
    "        \n",
    "    plt.plot(series[window:], label=\"Actual values\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.xticks(rotation = 70)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMovingAverage(data[''], 52, plot_intervals=False, scale=1.96, plot_anomalies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data.pkl'\n",
    "file = os.path.join(data_path, file_name)\n",
    "data.to_pickle(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
