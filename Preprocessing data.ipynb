{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '..//00_data/train_test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.join(path_to_data, 'X_train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_mostly_empty_columns(dataframe, missing_frac_threshold, to_keep):\n",
    "    frac_missing = pd.isna(dataframe).mean()\n",
    "    mostly_empty_columns = frac_missing[frac_missing > missing_frac_threshold].index\n",
    "\n",
    "    mostly_empty_columns = [col for col in mostly_empty_columns if col not in to_keep]\n",
    "\n",
    "    print('Dropping {} columns: {}'.format(len(mostly_empty_columns), mostly_empty_columns))\n",
    "    dataframe = dataframe.drop(mostly_empty_columns, axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = drop_mostly_empty_columns(X_train, 0.1, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_with_low_variance(dataframe, threshold):\n",
    "    print('Dropped columns with variance low than {}'.format(threshold))\n",
    "    dataframe.drop(dataframe.std()[dataframe.std() < threshold].index.values, axis=1, inplace = True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = drop_columns_with_low_variance(X_train, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_correlated_columns(dataframe, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataframe.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataframe.columns:\n",
    "                    del dataframe[colname] # deleting the column from the dataset\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = drop_highly_correlated_columns(X_train, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_data = '..//00_data/track_1'\n",
    "temp = pd.read_csv(os.path.join(path_to_data, 'meteo_1day.csv'))\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(temp.temperature_20cm_qual, temp.temperature_20cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 2, 3, 4, 8 - ошибочное значение\n",
    "# 5, 6, 7 - сомнительное значение\n",
    "# 9 - отсутствует значение\n",
    "for col in list(temp.filter(regex='qual')):\n",
    "    print(temp[col].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_incorrect_or_missing_values(dataframe):\n",
    "    # Находим колонки с признаками достоверности\n",
    "    for col in list(dataframe.filter(regex='qual')):\n",
    "        col_to_replace = col.rstrip(r'_qual')\n",
    "        dataframe.loc[dataframe[col] != 0.0, [col_to_replace]] = np.nan\n",
    "        #dataframe[col_to_replace][dataframe[col] == 9.0] =  np.nan\n",
    "        dataframe = dataframe.drop(col, 1)\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_2 = replace_incorrect_or_missing_values(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding for categorical values (define categorical!!)\n",
    "X_train = pd.get_dummies(data, columns=[''], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values by numeric values\n",
    "mlm = mlm.sort_values(['station_id', 'year', 'month'])\n",
    "num_cols = ['precipitation_observed',\n",
    "            'precipitation_corrected', \n",
    "            'precipitation_corrected_liquid',\n",
    "           'precipitation_corrected_mixed',\n",
    "           'precipitation_corrected_solid',\n",
    "           'sunshine_hours']\n",
    "mlm[num_cols] = mlm[num_cols + ['station_id']].groupby('station_id').\\\n",
    "    apply(lambda group: group.interpolate(method='index')).drop('station_id', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '..//00_data/track_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_coord = pd.read_csv(os.path.join(path_to_data, 'hydro_coord.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_height_difference\n",
    "# distance_from_source - расстояние от истока\n",
    "# z_null - высотная отметка нуля графика на гидропосте\n",
    "def calculate_height_difference(dataframe_with_stations):\n",
    "    dataframe_with_stations=dataframe_with_stations.sort_values(by = 'distance_from_source')\n",
    "    dataframe_with_stations['height_difference'] = dataframe_with_stations['z_null'] - dataframe_with_stations['z_null'].shift(1) \n",
    "    dataframe_with_stations['distance_to_previous'] = dataframe_with_stations['distance_from_source'] - dataframe_with_stations['distance_from_source'].shift(1)\n",
    "    dataframe_with_stations['height_diff_by_dist'] = dataframe_with_stations['height_difference']/dataframe_with_stations['distance_to_previous']\n",
    "    dataframe_with_stations.fillna(0, inplace = True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_coord = calculate_height_difference(hydro_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_coord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_coord.groupby(['station_id'])['distance_from_source'].value_counts(dropna = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
